{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-957c42f7361d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[0mmydata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCounter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyemotions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[0mx1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmydata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m \u001b[0memotiondetected\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mCounter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyemotions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmyemotion_acc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyemotion_acc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "# Imports the Google Cloud client library\n",
    "from google.cloud import vision\n",
    "\n",
    "#Emotions\n",
    "emo = ['Angry', 'Surprised','Sad', 'Happy', \"Under Exposed\", \"Blurred\", \"Headwear\"]\n",
    "likelihood_name = ('UNKNOWN', 'VERY_UNLIKELY', 'UNLIKELY', 'POSSIBLE',\n",
    "                    'LIKELY', 'VERY_LIKELY')\n",
    "from google.oauth2 import service_account\n",
    "cred = service_account.Credentials.from_service_account_file('My Project 57387-6393cb797528.json')\n",
    "\n",
    "# Instantiates a client\n",
    "vision_client = vision.ImageAnnotatorClient(credentials=cred)\n",
    "\n",
    "myemotions=[]\n",
    "myemotion_acc=dict.fromkeys(['Angry', 'Surprised','Sad', 'Happy', \"Under Exposed\", \"Blurred\", \"Headwear\",'No sentiment'],0)\n",
    "for i in myemotion_acc:\n",
    "    myemotion_acc[i]=[]\n",
    "compressRate = 1\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "\n",
    "direc=os.listdir()\n",
    "datafolder=[i for i in direc if 'output' in i]\n",
    "if len(datafolder)>0:\n",
    "    data=[int(re.search(r'\\d+',i).group()) for i in datafolder if re.search(r'\\d+',i)]\n",
    "    new1=max(data)+1\n",
    "    fldnaam='output{}'.format(new1)\n",
    "    os.mkdir('output{}'.format(new1))\n",
    "    os.chdir(os.getcwd()+'\\\\'+fldnaam)\n",
    "else:\n",
    "    os.mkdir('output1')\n",
    "    os.chdir(os.getcwd()+'\\\\'+'output1')\n",
    "_,img=video_capture.read()\n",
    "cv2.imshow('Video', img)\n",
    "filename='face1.jpg'\n",
    "out = cv2.VideoWriter('face.avi', fourcc, 20.0, (640,480))\n",
    "number=1\n",
    "while cv2.getWindowProperty('Video', 0) >= 0:\n",
    "    ret, img = video_capture.read()\n",
    "    \n",
    "    img.shape\n",
    "    img = cv2.resize(img, (0,0), fx=compressRate , fy=compressRate )\n",
    "    \n",
    "    \n",
    "    ok, buf = cv2.imencode(\".jpeg\",img)\n",
    "    image = vision.types.Image(content=buf.tostring())\n",
    "\n",
    "    response = vision_client.face_detection(image=image)\n",
    "    faces = response.face_annotations \n",
    "    for face in faces:\n",
    "        x = face.bounding_poly.vertices[0].x\n",
    "        y = face.bounding_poly.vertices[0].y\n",
    "        x2 = face.bounding_poly.vertices[2].x\n",
    "        y2 = face.bounding_poly.vertices[2].y\n",
    "        cv2.rectangle(img, (x, y), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "        sentiment = [likelihood_name[face.anger_likelihood],\n",
    "                    likelihood_name[face.surprise_likelihood],\n",
    "                    likelihood_name[face.sorrow_likelihood],\n",
    "                    likelihood_name[face.joy_likelihood],\n",
    "                    likelihood_name[face.under_exposed_likelihood],\n",
    "                    likelihood_name[face.blurred_likelihood],\n",
    "                    likelihood_name[face.headwear_likelihood]]\n",
    "\n",
    "        for item, item2 in zip(emo, sentiment):\n",
    "            print (item, \": \", item2)\n",
    "\n",
    "        string = 'No sentiment'\n",
    "\n",
    "        if not (all( item == 'VERY_UNLIKELY' for item in sentiment) ):\n",
    "            if any( item == 'VERY_LIKELY' for item in sentiment):\n",
    "                state = sentiment.index('VERY_LIKELY')\n",
    "                # the order of enum type Likelihood is:\n",
    "                #'LIKELY', 'POSSIBLE', 'UNKNOWN', 'UNLIKELY', 'VERY_LIKELY', 'VERY_UNLIKELY'\n",
    "                # it makes sense to do argmin if VERY_LIKELY is not present, one would espect that VERY_LIKELY\n",
    "                # would be the first in the order, but that's not the case, so this special case must be added\n",
    "            else:\n",
    "                state = np.argmin(sentiment)\n",
    "\n",
    "            string = emo[state]\n",
    "\n",
    "        cv2.putText(img,string, (x,y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,0,255), 2)\n",
    "        myemotions.append(string)\n",
    "        print(faces[0].detection_confidence) #acuracy\n",
    "        myemotion_acc[string].append(faces[0].detection_confidence)\n",
    "\n",
    "    cv2.imshow(\"Video\", img)\n",
    "    cv2.imwrite(filename,img)\n",
    "    number+=1\n",
    "    filename='face{}.jpg'.format(number)\n",
    "    cv2.waitKey(1)\n",
    "mydata=dict.fromkeys(['Angry', 'Surprised','Sad', 'Happy', \"Under Exposed\", \"Blurred\", \"Headwear\",'No sentiment'],0)\n",
    "mydata.update(dict(Counter(myemotions)))\n",
    "x1=list(range(len(mydata.keys())))\n",
    "emotiondetected=Counter(myemotions).most_common(1)[0][0]\n",
    "for i in myemotion_acc:\n",
    "    if len(myemotion_acc[i])>0:\n",
    "        myemotion_acc[i]=np.mean(np.array(myemotion_acc[i]))\n",
    "    else: myemotion_acc[i]=np.nan\n",
    "pos=['Happy','No sentiment','Sad']\n",
    "if pos.count(emotiondetected)!=0:\n",
    "    head='the vigilance is \"TRUTH\"'\n",
    "else:\n",
    "    head='the Vigilance is \"LIE\"'\n",
    "    \n",
    "\n",
    "plt.bar(x1,list(mydata.values()),tick_label=list(mydata.keys()))\n",
    "plt.xlabel('sentiments')\n",
    "plt.ylabel('scores')\n",
    "plt.title(head)\n",
    "out.write(img)\n",
    "plt.show()\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
